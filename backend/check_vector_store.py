#!/usr/bin/env python3
"""
æ£€æŸ¥åŒ»ç–—å‘é‡å­˜å‚¨ä¸­çš„æ–‡æ¡£å†…å®¹ï¼Œæ‰¾å‡ºæµ‹è¯•PDF
"""

import pickle
import json
from pathlib import Path

def check_vector_store(store_path):
    """æ£€æŸ¥æŒ‡å®šå‘é‡å­˜å‚¨ä¸­çš„æ–‡æ¡£"""
    print(f"\n=== æ£€æŸ¥å‘é‡å­˜å‚¨: {store_path.name} ===")
    
    # è¯»å–å…ƒæ•°æ®
    metadata_file = store_path / "metadata.json"
    if metadata_file.exists():
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        print(f"éƒ¨é—¨: {metadata['department']}")
        print(f"æ–‡æ¡£ç±»å‹: {metadata['document_type']}")
        print(f"ç–¾ç—…åˆ†ç±»: {metadata['disease_category']}")
        print(f"æ–‡æ¡£æ•°é‡: {metadata['document_count']}")
    
    # è¯»å–å‘é‡å­˜å‚¨çš„pickleæ–‡ä»¶
    pkl_file = store_path / "index.pkl"
    if pkl_file.exists():
        try:
            with open(pkl_file, 'rb') as f:
                data = pickle.load(f)
            
            print(f"æ•°æ®ç±»å‹: {type(data)}")
            
            # å¦‚æœæ˜¯tupleï¼Œå°è¯•è§£æ
            if isinstance(data, tuple):
                print(f"Tupleé•¿åº¦: {len(data)}")
                for i, item in enumerate(data):
                    print(f"  é¡¹ç›® {i}: {type(item)}")
                    
                # æ ¹æ®è¾“å‡ºï¼Œæ ¼å¼æ˜¯ (InMemoryDocstore, dict)
                if len(data) >= 2:
                    docstore, index_to_docstore_id = data[0], data[1]
                    print(f"æ–‡æ¡£å­˜å‚¨ç±»å‹: {type(docstore)}")
                    print(f"ç´¢å¼•æ˜ å°„ç±»å‹: {type(index_to_docstore_id)}")
                    
                    # InMemoryDocstoreçš„æ–‡æ¡£å­˜å‚¨åœ¨_dictä¸­
                    if hasattr(docstore, '_dict'):
                        docs = docstore._dict
                        print(f"å®é™…æ–‡æ¡£æ•°é‡: {len(docs)}")
                        
                        # æ£€æŸ¥æ¯ä¸ªæ–‡æ¡£
                        for i, (doc_id, doc) in enumerate(docs.items()):
                            print(f"\næ–‡æ¡£ {i+1} (ID: {doc_id}):")
                            content_preview = doc.page_content[:200] if len(doc.page_content) > 200 else doc.page_content
                            print(f"  å†…å®¹é¢„è§ˆ: {content_preview}")
                            print(f"  å…ƒæ•°æ®: {doc.metadata}")
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•PDF
                            if ("test PDF" in doc.page_content.lower() or 
                                "upload testing" in doc.page_content.lower() or
                                "sample text" in doc.page_content.lower()):
                                print(f"  âš ï¸  å‘ç°æµ‹è¯•PDF!")
                                return True
                    else:
                        print("  æ–‡æ¡£å­˜å‚¨æ²¡æœ‰_dictå±æ€§")
            
            # å¦‚æœæ˜¯FAISSå¯¹è±¡
            elif hasattr(data, 'docstore'):
                docstore = data.docstore
                print(f"æ–‡æ¡£å­˜å‚¨ç±»å‹: {type(docstore)}")
                
                if hasattr(docstore, '_dict'):
                    docs = docstore._dict
                    print(f"å®é™…æ–‡æ¡£æ•°é‡: {len(docs)}")
                    
                    # æ£€æŸ¥æ¯ä¸ªæ–‡æ¡£
                    for i, (doc_id, doc) in enumerate(docs.items()):
                        print(f"\næ–‡æ¡£ {i+1} (ID: {doc_id}):")
                        content_preview = doc.page_content[:200] if len(doc.page_content) > 200 else doc.page_content
                        print(f"  å†…å®¹é¢„è§ˆ: {content_preview}")
                        print(f"  å…ƒæ•°æ®: {doc.metadata}")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•PDF
                        if ("test PDF" in doc.page_content.lower() or 
                            "upload testing" in doc.page_content.lower() or
                            "sample text" in doc.page_content.lower()):
                            print(f"  âš ï¸  å‘ç°æµ‹è¯•PDF!")
                            return True
                else:
                    print("  æ–‡æ¡£å­˜å‚¨æ²¡æœ‰_dictå±æ€§")
            else:
                print("  æœªçŸ¥çš„æ•°æ®æ ¼å¼")
                
        except Exception as e:
            print(f"  è¯»å–å‘é‡å­˜å‚¨å¤±è´¥: {e}")
    else:
        print("  index.pklæ–‡ä»¶ä¸å­˜åœ¨")
    
    return False

def main():
    """ä¸»å‡½æ•°"""
    base_path = Path("/Users/jinlingxiao/Downloads/RAGAgent/backend/data/vector_stores")
    
    if not base_path.exists():
        print(f"å‘é‡å­˜å‚¨ç›®å½•ä¸å­˜åœ¨: {base_path}")
        return
    
    found_test_pdf = False
    
    # æ£€æŸ¥æ‰€æœ‰å‘é‡å­˜å‚¨
    for store_dir in base_path.iterdir():
        if store_dir.is_dir() and "å¿ƒè¡€ç®¡ç§‘" in store_dir.name:
            if check_vector_store(store_dir):
                found_test_pdf = True
    
    if found_test_pdf:
        print("\nğŸš¨ å‘ç°æµ‹è¯•PDFè¢«é”™è¯¯ç´¢å¼•åˆ°åŒ»ç–—çŸ¥è¯†åº“ä¸­!")
    else:
        print("\nâœ… æœªå‘ç°æµ‹è¯•PDF")

if __name__ == "__main__":
    main()