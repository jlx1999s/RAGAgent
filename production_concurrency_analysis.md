# ç”Ÿäº§ç¯å¢ƒå¹¶å‘å¤„ç†èƒ½åŠ›åˆ†ææŠ¥å‘Š

## ğŸ“Š å½“å‰ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### åç«¯æ¶æ„
- **æ¡†æ¶**: FastAPI + Uvicorn
- **å¼‚æ­¥æ”¯æŒ**: åŸºäºPython asyncio
- **æ•°æ®å­˜å‚¨**: Redis + FAISSå‘é‡æ•°æ®åº“
- **ç¼“å­˜æœºåˆ¶**: å†…å­˜LRUç¼“å­˜ + RedisçŠ¶æ€å­˜å‚¨

### æœåŠ¡éƒ¨ç½²
- **åŒ»ç”Ÿç«¯**: åç«¯8000ç«¯å£ï¼Œå‰ç«¯3000ç«¯å£
- **æ‚£è€…ç«¯**: åç«¯8001ç«¯å£ï¼Œå‰ç«¯3001ç«¯å£

## ğŸ” å¹¶å‘å¤„ç†æœºåˆ¶åˆ†æ

### 1. WebæœåŠ¡å™¨å¹¶å‘èƒ½åŠ›

#### å½“å‰é…ç½®
```bash
# å¯åŠ¨å‘½ä»¤
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
uvicorn app:app --host 0.0.0.0 --port 8001 --reload
```

#### é—®é¢˜è¯†åˆ«
- âŒ **å•è¿›ç¨‹å•çº¿ç¨‹**: ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œæ— workersè®¾ç½®
- âŒ **å¼€å‘æ¨¡å¼**: å¯ç”¨äº†--reloadï¼Œä¸é€‚åˆç”Ÿäº§ç¯å¢ƒ
- âŒ **æ— è´Ÿè½½å‡è¡¡**: å•å®ä¾‹è¿è¡Œï¼Œå­˜åœ¨å•ç‚¹æ•…éšœé£é™©

#### ç”Ÿäº§ç¯å¢ƒå»ºè®®
```bash
# æ¨èç”Ÿäº§é…ç½®
uvicorn app:app --host 0.0.0.0 --port 8000 --workers 4 --worker-class uvicorn.workers.UvicornWorker
# æˆ–ä½¿ç”¨Gunicorn
gunicorn app:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### 2. æ•°æ®åº“è¿æ¥æ± 

#### Redisè¿æ¥
```python
# å½“å‰å®ç° - backend/patient/services/state_store.py
_redis = Redis.from_url(url, decode_responses=True)
```

**é—®é¢˜**:
- âŒ **æ— è¿æ¥æ± é…ç½®**: ä½¿ç”¨é»˜è®¤è¿æ¥æ± è®¾ç½®
- âŒ **æ— è¿æ¥é™åˆ¶**: å¯èƒ½å¯¼è‡´è¿æ¥è€—å°½
- âŒ **æ— è¶…æ—¶è®¾ç½®**: å¯èƒ½å¯¼è‡´é•¿æ—¶é—´é˜»å¡

**æ”¹è¿›å»ºè®®**:
```python
_redis = Redis.from_url(
    url, 
    decode_responses=True,
    max_connections=20,
    socket_connect_timeout=5,
    socket_timeout=5,
    retry_on_timeout=True
)
```

#### FAISSå‘é‡æ•°æ®åº“
```python
# å½“å‰å®ç° - å»¶è¿ŸåŠ è½½æœºåˆ¶
def _load_vector_store(self, store_key: str) -> Optional[FAISS]:
    if store_key in self.vector_stores:
        return self.vector_stores[store_key]
```

**ä¼˜åŠ¿**:
- âœ… **å†…å­˜ç¼“å­˜**: å·²åŠ è½½çš„å‘é‡å­˜å‚¨ä¿å­˜åœ¨å†…å­˜ä¸­
- âœ… **å»¶è¿ŸåŠ è½½**: æŒ‰éœ€åŠ è½½ï¼ŒèŠ‚çœå†…å­˜

**æ½œåœ¨é—®é¢˜**:
- âš ï¸ **çº¿ç¨‹å®‰å…¨**: FAISSæœ¬èº«ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„
- âš ï¸ **å†…å­˜å ç”¨**: å¤§é‡å‘é‡å­˜å‚¨å¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³

### 3. ç¼“å­˜ç³»ç»Ÿ

#### å†…å­˜ç¼“å­˜
```python
# å½“å‰å®ç° - LRUç¼“å­˜æœºåˆ¶
class CacheService:
    def __init__(self, max_size: int = 1000, default_ttl: int = 3600):
        self.max_size = max_size
        self._cache: Dict[str, CacheEntry] = {}
```

**ä¼˜åŠ¿**:
- âœ… **LRUæ·˜æ±°ç­–ç•¥**: è‡ªåŠ¨æ¸…ç†æœ€å°‘ä½¿ç”¨çš„ç¼“å­˜
- âœ… **TTLæ”¯æŒ**: ä¸åŒç±»å‹ç¼“å­˜æœ‰ä¸åŒè¿‡æœŸæ—¶é—´
- âœ… **ç»Ÿè®¡ä¿¡æ¯**: æä¾›ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡

**é™åˆ¶**:
- âš ï¸ **å•è¿›ç¨‹ç¼“å­˜**: å¤šè¿›ç¨‹é—´æ— æ³•å…±äº«ç¼“å­˜
- âš ï¸ **å†…å­˜é™åˆ¶**: å›ºå®šå¤§å°é™åˆ¶(1000æ¡ç›®)

### 4. å¼‚æ­¥å¤„ç†èƒ½åŠ›

#### å¹¶è¡ŒæŸ¥è¯¢æ”¯æŒ
```python
# å·²å®ç°å¹¶è¡Œå¤„ç†æµ‹è¯•
async def test_parallel_processing():
    tasks = [
        process_query(query, f"parallel_test_{i}")
        for i, query in enumerate(queries)
    ]
    parallel_results = await asyncio.gather(*tasks)
```

**ä¼˜åŠ¿**:
- âœ… **å¼‚æ­¥æ”¯æŒ**: ä½¿ç”¨asyncio.gatherè¿›è¡Œå¹¶è¡Œå¤„ç†
- âœ… **æ€§èƒ½æµ‹è¯•**: å·²æœ‰å¹¶è¡Œvsä¸²è¡Œæ€§èƒ½å¯¹æ¯”

#### çº¿ç¨‹æ± ä½¿ç”¨
```python
# çŸ¥è¯†å›¾è°±å¢å¼ºä¸­çš„çº¿ç¨‹æ± 
with ThreadPoolExecutor(max_workers=2) as executor:
    entities_future = executor.submit(
        kg_service.extract_entities_from_text, question
    )
```

**ä¼˜åŠ¿**:
- âœ… **CPUå¯†é›†ä»»åŠ¡**: ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†å®ä½“æå–
- âœ… **èµ„æºæ§åˆ¶**: é™åˆ¶æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°

## ğŸ“ˆ æ€§èƒ½ç“¶é¢ˆåˆ†æ

### 1. é«˜å¹¶å‘åœºæ™¯ä¸‹çš„é—®é¢˜

#### å†…å­˜ä½¿ç”¨
- **å‘é‡å­˜å‚¨**: æ¯ä¸ªFAISSç´¢å¼•å ç”¨å¤§é‡å†…å­˜
- **ç¼“å­˜ç³»ç»Ÿ**: 1000æ¡ç›®é™åˆ¶å¯èƒ½ä¸è¶³
- **ä¼šè¯çŠ¶æ€**: Rediså­˜å‚¨ç”¨æˆ·ä¼šè¯ï¼Œéœ€è¦åˆç†TTL

#### I/Oç“¶é¢ˆ
- **æ–‡ä»¶è¯»å–**: FAISSç´¢å¼•æ–‡ä»¶åŠ è½½
- **ç½‘ç»œè¯·æ±‚**: å¤§æ¨¡å‹APIè°ƒç”¨
- **Redisè®¿é—®**: çŠ¶æ€å­˜å‚¨å’Œæ£€ç´¢

### 2. å¹¶å‘é™åˆ¶

#### å½“å‰é™åˆ¶
- **å•è¿›ç¨‹**: æ— æ³•å……åˆ†åˆ©ç”¨å¤šæ ¸CPU
- **GILé™åˆ¶**: Pythonå…¨å±€è§£é‡Šå™¨é”å½±å“CPUå¯†é›†ä»»åŠ¡
- **è¿æ¥æ•°**: Rediså’ŒHTTPè¿æ¥æ•°é™åˆ¶

## ğŸš€ ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–å»ºè®®

### 1. æœåŠ¡å™¨é…ç½®ä¼˜åŒ–

#### Uvicorn/Gunicorné…ç½®
```bash
# æ¨èé…ç½®
gunicorn app:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --worker-connections 1000 \
  --max-requests 1000 \
  --max-requests-jitter 100 \
  --timeout 30 \
  --bind 0.0.0.0:8000
```

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# ç”Ÿäº§ç¯å¢ƒå˜é‡
export WORKERS=4
export MAX_CONNECTIONS=1000
export REDIS_MAX_CONNECTIONS=20
export CACHE_MAX_SIZE=5000
export VECTOR_STORE_CACHE_SIZE=50
```

### 2. æ•°æ®åº“ä¼˜åŒ–

#### Redisé…ç½®
```python
# ä¼˜åŒ–çš„Redisè¿æ¥æ± 
redis_pool = ConnectionPool(
    host='localhost',
    port=6379,
    db=0,
    max_connections=20,
    socket_connect_timeout=5,
    socket_timeout=5,
    retry_on_timeout=True
)
_redis = Redis(connection_pool=redis_pool)
```

#### FAISSä¼˜åŒ–
```python
# å‘é‡å­˜å‚¨é¢„åŠ è½½å’Œç¼“å­˜ç®¡ç†
class OptimizedVectorStore:
    def __init__(self, max_stores=50):
        self.max_stores = max_stores
        self.store_cache = {}
        self.access_times = {}
        self._lock = asyncio.Lock()
    
    async def get_store(self, store_key):
        async with self._lock:
            # å®ç°LRUç¼“å­˜é€»è¾‘
            pass
```

### 3. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

#### åˆ†å±‚ç¼“å­˜
```python
# L1: å†…å­˜ç¼“å­˜ (çƒ­æ•°æ®)
# L2: Redisç¼“å­˜ (æ¸©æ•°æ®)
# L3: æ•°æ®åº“/æ–‡ä»¶ (å†·æ•°æ®)

class TieredCacheService:
    def __init__(self):
        self.l1_cache = {}  # å†…å­˜ç¼“å­˜
        self.l2_cache = redis_client  # Redisç¼“å­˜
```

### 4. ç›‘æ§å’Œé™æµ

#### è¯·æ±‚é™æµ
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/api/v1/medical/qa")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿ10æ¬¡è¯·æ±‚
async def medical_qa(request: Request, ...):
    pass
```

#### æ€§èƒ½ç›‘æ§
```python
# PrometheusæŒ‡æ ‡
from prometheus_client import Counter, Histogram, Gauge

REQUEST_COUNT = Counter('requests_total', 'Total requests')
REQUEST_LATENCY = Histogram('request_duration_seconds', 'Request latency')
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Active connections')
```

## ğŸ“Š å®¹é‡è§„åˆ’å»ºè®®

### ç¡¬ä»¶èµ„æº
- **CPU**: 4-8æ ¸å¿ƒï¼Œæ”¯æŒå¤šè¿›ç¨‹éƒ¨ç½²
- **å†…å­˜**: 16-32GBï¼Œç”¨äºå‘é‡å­˜å‚¨å’Œç¼“å­˜
- **å­˜å‚¨**: SSDï¼Œå¿«é€ŸI/Oè®¿é—®
- **ç½‘ç»œ**: åƒå…†ç½‘ç»œï¼Œæ”¯æŒé«˜å¹¶å‘

### å¹¶å‘èƒ½åŠ›é¢„ä¼°
- **å•è¿›ç¨‹**: ~100-200å¹¶å‘è¿æ¥
- **4è¿›ç¨‹**: ~400-800å¹¶å‘è¿æ¥
- **è´Ÿè½½å‡è¡¡**: å¯çº¿æ€§æ‰©å±•

### æ‰©å±•ç­–ç•¥
1. **å‚ç›´æ‰©å±•**: å¢åŠ å•æœºèµ„æº
2. **æ°´å¹³æ‰©å±•**: å¤šå®ä¾‹éƒ¨ç½² + è´Ÿè½½å‡è¡¡
3. **å¾®æœåŠ¡åŒ–**: æ‹†åˆ†ä¸åŒåŠŸèƒ½æ¨¡å—
4. **ç¼“å­˜é›†ç¾¤**: Redisé›†ç¾¤éƒ¨ç½²

## âš ï¸ é£é™©è¯„ä¼°

### é«˜é£é™©é¡¹
1. **å•ç‚¹æ•…éšœ**: å•å®ä¾‹éƒ¨ç½²
2. **å†…å­˜æ³„æ¼**: å‘é‡å­˜å‚¨ç¼“å­˜æ— é™å¢é•¿
3. **è¿æ¥è€—å°½**: Redisè¿æ¥æ± é…ç½®ä¸å½“

### ä¸­é£é™©é¡¹
1. **ç¼“å­˜ç©¿é€**: å¤§é‡æ— æ•ˆæŸ¥è¯¢
2. **çƒ­ç‚¹æ•°æ®**: æŸäº›æŸ¥è¯¢è¿‡äºé¢‘ç¹
3. **GCå‹åŠ›**: å¤§å¯¹è±¡é¢‘ç¹åˆ›å»ºé”€æ¯

### å»ºè®®æªæ–½
1. **å¥åº·æ£€æŸ¥**: å®ç°æœåŠ¡å¥åº·æ£€æŸ¥ç«¯ç‚¹
2. **ç†”æ–­æœºåˆ¶**: é˜²æ­¢çº§è”æ•…éšœ
3. **ä¼˜é›…å…³é—­**: å¤„ç†è¿›ç¨‹ä¿¡å·ï¼Œå®‰å…¨å…³é—­æœåŠ¡
4. **æ—¥å¿—ç›‘æ§**: å®Œå–„çš„æ—¥å¿—è®°å½•å’Œç›‘æ§

## ğŸ“ æ€»ç»“

å½“å‰ç³»ç»Ÿåœ¨å¼€å‘ç¯å¢ƒä¸‹è¿è¡Œè‰¯å¥½ï¼Œä½†åœ¨ç”Ÿäº§ç¯å¢ƒä¸‹éœ€è¦è¿›è¡Œä»¥ä¸‹å…³é”®ä¼˜åŒ–ï¼š

1. **ç«‹å³éœ€è¦**: é…ç½®å¤šè¿›ç¨‹éƒ¨ç½²ï¼Œä¼˜åŒ–Redisè¿æ¥æ± 
2. **çŸ­æœŸä¼˜åŒ–**: å®ç°åˆ†å±‚ç¼“å­˜ï¼Œæ·»åŠ è¯·æ±‚é™æµ
3. **é•¿æœŸè§„åˆ’**: å¾®æœåŠ¡åŒ–æ¶æ„ï¼Œé›†ç¾¤éƒ¨ç½²

é€šè¿‡è¿™äº›ä¼˜åŒ–ï¼Œç³»ç»Ÿå¯ä»¥æ”¯æŒæ•°ç™¾åˆ°æ•°åƒçš„å¹¶å‘ç”¨æˆ·è®¿é—®ã€‚